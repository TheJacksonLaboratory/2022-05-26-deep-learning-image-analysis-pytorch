{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "177db554-5724-456f-9889-e63382b7c40a",
   "metadata": {},
   "source": [
    "# **Deep learning for image analysis with Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34661982-88ba-41d0-b84d-04f47dbd478b",
   "metadata": {},
   "source": [
    "#### Fernando Cervantes, Systems Analyst I, Imaging Solutions, Research IT\n",
    "#### fernando.cervantes@jax.org    (slack) @fernando.cervantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dfa69a-253b-4de8-b057-8c6fe131ffed",
   "metadata": {},
   "source": [
    "## 6 Monitoring and logging the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b85f28-6b38-4698-adae-f4c2fe4fa8da",
   "metadata": {},
   "source": [
    "It is important to track the training process. By doing that, we can detect interesting behavior of our network, possible failures, and even *overfitting*.<br>\n",
    "This also helps to save the results of different experiments performed using distinct configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c55f70-f389-4082-a1d3-0e14262a5310",
   "metadata": {},
   "source": [
    "### 6.1 _Logging the network performance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "849d2abb-69d6-41da-8fcc-aee4d199d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR100\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "cifar_data = CIFAR100(root=r'/home/cervaf/data', # '/mnt/data'\n",
    "                             download=False,\n",
    "                             train=True,\n",
    "                             transform=ToTensor()\n",
    "                            )\n",
    "\n",
    "cifar_loader = DataLoader(cifar_data,\n",
    "                              batch_size=128,\n",
    "                              shuffle=True,\n",
    "                              pin_memory=True\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a6ab29-f018-40c6-bdfc-5bfad25baaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        \"\"\"\n",
    "        Always call the initialization function from the nn.Module parent class.\n",
    "        This way all parameters from the operations defined as members of *this* class are tracked for their optimization.\n",
    "        \"\"\"\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=5)\n",
    "        self.sub_1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.sub_2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc_1 = nn.Linear(in_features=5*5*16, out_features=120)\n",
    "        self.fc_2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc_3 = nn.Linear(in_features=84, out_features=num_classes)\n",
    "        \n",
    "        self.act_fn = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolution layers to extract feature maps with image context\n",
    "        fx = self.act_fn(self.conv_1(x))\n",
    "        fx = self.sub_1(fx)\n",
    "        \n",
    "        fx = self.act_fn(self.conv_2(fx))\n",
    "        fx = self.sub_2(fx)\n",
    "        \n",
    "        # Flatten the feature maps to perform linear operations\n",
    "        fx = fx.view(-1, 16*5*5)\n",
    "        \n",
    "        fx = self.act_fn(self.fc_1(fx))\n",
    "        fx = self.act_fn(self.fc_2(fx))\n",
    "        y = self.fc_3(fx)\n",
    "        \n",
    "        return y\n",
    "\n",
    "net = LeNet(in_channels=3, num_classes=100)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "net.cuda()\n",
    "criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "583c78f4-f39e-41e8-9618-b7c9c9f59459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    params=net.parameters(),\n",
    "    lr=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f5b23-be32-4296-9285-3df0859fe2d3",
   "metadata": {},
   "source": [
    "***\n",
    "Now that we have set up our experiment, lets create a summary writer for our training stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9625d70c-4254-4731-b1f3-68d1a7414ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9495c77e-aa33-4047-90be-90fb35aae8ec",
   "metadata": {},
   "source": [
    "Create a summary writter using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e944094a-9d99-4429-987a-2a089cecaf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/LR_0_001_BATCH_128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9367f0c3-b1ef-4a8e-874b-a50c4deee927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net.train()\n",
    "\n",
    "for e  in range(10):\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    \n",
    "    for i, (x, t) in enumerate(cifar_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.cuda()\n",
    "        t = t.cuda()\n",
    "        \n",
    "        y = net(x)\n",
    "\n",
    "        loss = criterion(y, t)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        curr_acc = torch.sum(y.argmax(dim=1) == t)\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        avg_acc += curr_acc\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        writer.add_scalar('training loss', loss.item(), e * len(cifar_loader) + i)\n",
    "        writer.add_scalar('training acc', curr_acc / x.size(0), e * len(cifar_loader) + i)\n",
    "\n",
    "    avg_loss = avg_loss / len(cifar_loader)\n",
    "    avg_acc = avg_acc / len(cifar_data)\n",
    "    writer.add_scalar('training loss', loss.item(), e)\n",
    "    writer.add_scalar('training loss', loss.item(), e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc6ce340-d509-405b-a983-c2922a0c6578",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'lenet_700epochs_20220519.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fac062-202a-49ab-be2a-d349a7355b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
