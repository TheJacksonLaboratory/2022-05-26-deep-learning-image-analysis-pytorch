{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "177db554-5724-456f-9889-e63382b7c40a",
   "metadata": {},
   "source": [
    "# **Deep learning for image analysis with Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34661982-88ba-41d0-b84d-04f47dbd478b",
   "metadata": {},
   "source": [
    "#### Fernando Cervantes, Systems Analyst I, Imaging Solutions, Research IT\n",
    "#### fernando.cervantes@jax.org    (slack) @fernando.cervantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dfa69a-253b-4de8-b057-8c6fe131ffed",
   "metadata": {},
   "source": [
    "## 6 Monitoring and logging the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b85f28-6b38-4698-adae-f4c2fe4fa8da",
   "metadata": {},
   "source": [
    "It is important to track the training process. By doing that, we can detect interesting behavior of our network, possible failures, and even *overfitting*.<br>\n",
    "This also helps to save the results of different experiments performed using distinct configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c55f70-f389-4082-a1d3-0e14262a5310",
   "metadata": {},
   "source": [
    "### 6.1 _Logging the network performance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb3467bc-8312-4caa-b84b-be41c25a20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7adcc228-6b49-4c45-a66a-163eac122175",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_transform_list = [\n",
    "    ToTensor()\n",
    "]\n",
    "\n",
    "cifar_transform = Compose(cifar_transform_list)\n",
    "\n",
    "cifar_trn_dataset = CIFAR100(root='/home/cervaf/data', download=False, train=True, transform=cifar_transform)\n",
    "cifar_trn_loader = DataLoader(cifar_trn_dataset, batch_size=128, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "499ad569-07a9-4720-8be7-26fec6ad191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4a6ab29-f018-40c6-bdfc-5bfad25baaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample=False):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        \n",
    "        if downsample:\n",
    "            self.conv_1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "            self.downsample = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=2, padding=0, bias=False)\n",
    "        else:\n",
    "            self.conv_1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.downsample = nn.Identity()\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False)        \n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = self.downsample(x)\n",
    "        \n",
    "        fx = self.relu(self.conv_1(x))\n",
    "        fx = self.bn1(fx)\n",
    "        \n",
    "        fx = self.conv_2(fx)\n",
    "        fx = self.bn2(fx)\n",
    "\n",
    "        fx = self.relu(fx + identity)\n",
    "        \n",
    "        return fx\n",
    "\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(num_features=64) \n",
    "        self.relu = nn.ReLU()\n",
    "        # Output is 32x32x64\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            ResNetBlock(in_channels=64, out_channels=64, downsample=True),\n",
    "            ResNetBlock(in_channels=64, out_channels=64, downsample=False),\n",
    "            ResNetBlock(in_channels=64, out_channels=128, downsample=True),\n",
    "            ResNetBlock(in_channels=128, out_channels=128, downsample=False),\n",
    "            ResNetBlock(in_channels=128, out_channels=256, downsample=True),\n",
    "            ResNetBlock(in_channels=256, out_channels=256, downsample=False),\n",
    "            ResNetBlock(in_channels=256, out_channels=512, downsample=True),\n",
    "            ResNetBlock(in_channels=512, out_channels=512, downsample=False)\n",
    "        )\n",
    "        # Output is 2x2x512\n",
    "        \n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        # Output is 1x1x512\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=512, out_features=num_classes, bias=True)\n",
    "        # output is 1xnum_classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        fx = self.bn(self.relu(self.embedding(x)))\n",
    "        \n",
    "        fx = self.layers(fx)\n",
    "        \n",
    "        fx = self.avg_pool(fx)\n",
    "        \n",
    "        logits = self.fc(fx.view(-1, 512))\n",
    "        \n",
    "        return logits\n",
    "\n",
    "net = ResNet(in_channels=3, num_classes=100)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "net.cuda()\n",
    "criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "583c78f4-f39e-41e8-9618-b7c9c9f59459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    params=net.parameters(),\n",
    "    lr=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f5b23-be32-4296-9285-3df0859fe2d3",
   "metadata": {},
   "source": [
    "***\n",
    "Now that we have set up our experiment, lets create a summary writer for our training stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9625d70c-4254-4731-b1f3-68d1a7414ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9495c77e-aa33-4047-90be-90fb35aae8ec",
   "metadata": {},
   "source": [
    "Create a summary writter using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e944094a-9d99-4429-987a-2a089cecaf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/LR_0.001_BATCH_128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b67bcb7f-ce89-482f-9ed8-eba427474154",
   "metadata": {},
   "outputs": [],
   "source": [
    "starter = torch.cuda.Event(enable_timing=True)\n",
    "ender = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9367f0c3-b1ef-4a8e-874b-a50c4deee927",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] 3.65062169\n",
      "[Epoch 01] 2.88800209\n",
      "[Epoch 02] 2.36192711\n",
      "[Epoch 03] 1.96028529\n",
      "[Epoch 04] 1.59957976\n",
      "[Epoch 05] 1.22611987\n",
      "[Epoch 06] 0.87889902\n",
      "[Epoch 07] 0.54227505\n",
      "[Epoch 08] 0.33578738\n",
      "[Epoch 09] 0.21201504\n",
      "[Epoch 10] 0.20038928\n",
      "[Epoch 11] 0.17722930\n",
      "[Epoch 12] 0.15801338\n",
      "[Epoch 13] 0.14833670\n",
      "[Epoch 14] 0.12397254\n",
      "[Epoch 15] 0.10777072\n",
      "[Epoch 16] 0.09825277\n",
      "[Epoch 17] 0.13012789\n",
      "[Epoch 18] 0.11447810\n",
      "[Epoch 19] 0.08842344\n",
      "[Epoch 20] 0.07526941\n",
      "[Epoch 21] 0.08866941\n",
      "[Epoch 22] 0.09730977\n",
      "[Epoch 23] 0.09207045\n",
      "[Epoch 24] 0.07990088\n",
      "[Epoch 25] 0.06634067\n",
      "[Epoch 26] 0.07914605\n",
      "[Epoch 27] 0.06461058\n",
      "[Epoch 28] 0.05971114\n",
      "[Epoch 29] 0.07999803\n",
      "[Epoch 30] 0.06231711\n",
      "[Epoch 31] 0.05414208\n",
      "[Epoch 32] 0.05418844\n",
      "[Epoch 33] 0.06799812\n",
      "[Epoch 34] 0.07609604\n",
      "[Epoch 35] 0.05467035\n",
      "[Epoch 36] 0.04762390\n",
      "[Epoch 37] 0.05371990\n",
      "[Epoch 38] 0.05767364\n",
      "[Epoch 39] 0.05375689\n",
      "[Epoch 40] 0.04962738\n",
      "[Epoch 41] 0.04518812\n",
      "[Epoch 42] 0.04953536\n",
      "[Epoch 43] 0.04910351\n",
      "[Epoch 44] 0.03543905\n",
      "[Epoch 45] 0.04314062\n",
      "[Epoch 46] 0.05171530\n",
      "[Epoch 47] 0.05096803\n",
      "[Epoch 48] 0.04794429\n",
      "[Epoch 49] 0.03370862\n",
      "[Epoch 50] 0.03451495\n",
      "[Epoch 51] 0.04013908\n",
      "[Epoch 52] 0.03925790\n",
      "[Epoch 53] 0.04407114\n",
      "[Epoch 54] 0.04067117\n",
      "[Epoch 55] 0.03953718\n",
      "[Epoch 56] 0.03169098\n",
      "[Epoch 57] 0.03132177\n",
      "[Epoch 58] 0.03371198\n",
      "[Epoch 59] 0.03776361\n",
      "[Epoch 60] 0.03959062\n",
      "[Epoch 61] 0.03376758\n",
      "[Epoch 62] 0.02652608\n",
      "[Epoch 63] 0.02620476\n",
      "[Epoch 64] 0.03458314\n",
      "[Epoch 65] 0.04330012\n",
      "[Epoch 66] 0.03795301\n",
      "[Epoch 67] 0.02774782\n",
      "[Epoch 68] 0.02349931\n",
      "[Epoch 69] 0.02845003\n",
      "[Epoch 70] 0.03517196\n",
      "[Epoch 71] 0.03546220\n",
      "[Epoch 72] 0.02880258\n",
      "[Epoch 73] 0.02689426\n",
      "[Epoch 74] 0.02865353\n",
      "[Epoch 75] 0.02268432\n",
      "[Epoch 76] 0.03183872\n",
      "[Epoch 77] 0.03670000\n",
      "[Epoch 78] 0.02411187\n",
      "[Epoch 79] 0.02367042\n",
      "[Epoch 80] 0.02023517\n",
      "[Epoch 81] 0.02761166\n",
      "[Epoch 82] 0.03043887\n",
      "[Epoch 83] 0.02376364\n",
      "[Epoch 84] 0.02586239\n",
      "[Epoch 85] 0.02358760\n",
      "[Epoch 86] 0.02071400\n",
      "[Epoch 87] 0.02107355\n",
      "[Epoch 88] 0.02448655\n",
      "[Epoch 89] 0.02208858\n",
      "[Epoch 90] 0.02601843\n",
      "[Epoch 91] 0.02710170\n",
      "[Epoch 92] 0.02898848\n",
      "[Epoch 93] 0.01968700\n",
      "[Epoch 94] 0.01625939\n",
      "[Epoch 95] 0.01865933\n",
      "[Epoch 96] 0.02371779\n",
      "[Epoch 97] 0.03498227\n",
      "[Epoch 98] 0.01883862\n",
      "[Epoch 99] 0.01935449\n"
     ]
    }
   ],
   "source": [
    "trn_loss = []\n",
    "trn_avg_acc = 0\n",
    "net.train()\n",
    "\n",
    "for e  in range(100):\n",
    "    avg_loss = 0\n",
    "    for i, (x, t) in enumerate(cifar_trn_loader):\n",
    "        starter.record()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.cuda()\n",
    "        t = t.cuda()\n",
    "        \n",
    "        y = net(x)\n",
    "\n",
    "        loss = criterion(y, t)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        trn_loss.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        ender.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        trn_avg_acc += sklearn.metrics.accuracy_score(t.cpu().numpy(), y.cpu().argmax(dim=1).numpy(), normalize=False)\n",
    "            \n",
    "        e_time = starter.elapsed_time(ender)\n",
    "        \n",
    "        writer.add_scalar('batch time', e_time, e * len(cifar_trn_loader) + i)\n",
    "        writer.add_scalar('training loss', loss.item(), e * len(cifar_trn_loader) + i)\n",
    "        writer.add_scalar('training acc', sklearn.metrics.accuracy_score(t.cpu().numpy(), y.cpu().argmax(dim=1).numpy(), normalize=True), e * len(cifar_trn_loader) + i)\n",
    "\n",
    "    avg_loss = avg_loss / len(cifar_trn_loader)\n",
    "    print('[Epoch %02i] %.8f' % (e, avg_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc6ce340-d509-405b-a983-c2922a0c6578",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'resnet_100epochs_20220420.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fac062-202a-49ab-be2a-d349a7355b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
